{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit learn Documentation\n",
    "http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Terms\n",
    "\n",
    "Margin = distance between line and nearest point of either class\n",
    "\n",
    "### Intuition\n",
    "\n",
    "SVMS separate classes. They can be used for classification, regression, and outlier detection.\n",
    "\n",
    "The margin is maximized- that is the distance between the nearest points of both classes is maximized.\n",
    "If maximized, the robustness is higher.\n",
    "\n",
    "SVMS put first and foremost the minimization of classification error. \n",
    "\n",
    "#### Non-linearity\n",
    "\n",
    "- SVMs can be \"non-linear\" if you look at 2 dimensions!\n",
    "- Third dimension calculated by X^2 + y^2\n",
    "- This third dimension allows for linear hyperplanes for data not obsiously separatable in 2-d\n",
    "- Can also add similar 3rd Ds, such as |x| or |y|\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "- Memory Effecient\n",
    "- Can handle high dimensionality to a reasonable degree\n",
    "- Versatile: use kernel functions to specify descision function\n",
    "\n",
    "#### Disadvantages\n",
    "\n",
    "- To avoid over-fitting when have high dimensionality, need to use right kernel function and regularization term\n",
    "- Not directly provide probability estimates\n",
    "\n",
    "#### Outliers\n",
    "\n",
    "SVMs tolerate individual outliers. They can identify outliers and will create the best margin possible not taking into account outliers.\n",
    "\n",
    "Thus, they ignore outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 1.,  1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices of support vectors\n",
    "clf.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of support vectors for each class\n",
    "clf.n_support_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can make changes in input space to increase size of input space\n",
    "- This allows formerly non-linear seperable data to linear separable\n",
    "- This can result in a decision line that is non-linear\n",
    "\n",
    "#### Key Parameters\n",
    "\n",
    "- C \"gamma\": defines how far influence of single training set reaches. \n",
    "- Low values will allow for far reach\n",
    "- High values will allow for close reach. \n",
    "- so higher values will result in potential over fitting and more jagged hyperplane.\n",
    "\n",
    "- Kernel: can be linear, rbf, poly, etc.\n",
    "- for rbf kernel need to raise the C value\n",
    "\n",
    "#### How to stop overfitting\n",
    "- Need to tune parameters to not overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
